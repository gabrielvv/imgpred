{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Datascience rapport #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce rapport est de présenter tout le travail réalisé par les élèves Gabriel Vautrin et Mickael Bordage sur un sujet de data science qui met en évidence les différentes techniques vue précédemment en cours\n",
    "\n",
    "**Sujet :** Mise en place d'un classifieur d'image qui à pour but de détecter la présence de chat sur une photo\n",
    "\n",
    "\n",
    "Dans un premier temps, nous détaillerons toutes les étapes transitoires qui nous ont permis de réaliser cette étude\n",
    "Pour cela nous présenterons la partie collecte de dataset puis les différents choix techniques qui nous ont amené à utiliser tel ou tel classifieur.\n",
    "Enfin nous conclurons avec les résultats obtenues ainsi que les axes d'amélioration de cette étude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecte des Datasets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la recherche de dataset, il a fallu trouver un ensemble de dataset assez conséquent pour pouvoir avoir un entrainement du classifieur qui couvre un grand nombre de cas possible. Pour les images représentant des chats nous nous sommes basés sur google Image grâce à un script pour sortir les urls et les télécharger par la suite. Nous avons ensuite trouver des datasets existant sur d’autres plateformes. Pour les images non chat la recherche à été moins compliqué car n'importe quel dataset peut être utilisé.\n",
    "La correspondance entre le nombre d'image chat et les non chat est importante car cela permet d'avoir une nombre équitable de résultat entre ces deux types.\n",
    "\n",
    "Le nombre d'image est une notion important car il faut pourvoir avoir assez de dataset pour l'entrainement ce qui augmente considérablement le temps de traitement. Il faut donc trouver une équilibre entre le nombre d'image et le temps d'etnrainement du classifieur \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chat\n",
    "\n",
    "| Source | Total |\n",
    "| --------------| -----------|\n",
    "| [google image](https://www.google.com/search?q=cat&source=lnms&tbm=isch&sa=X&ved=0ahUKEwi8oKaNw5jYAhWG8RQKHVfoD7kQ_AUICigB&biw=1920&bih=968) | 610 |\n",
    "| [imagenet](https://www.image-net.org/synset?wnid=n02121620) | 861 |\n",
    "| [kaggle](https://www.kaggle.com/c/dogs-vs-cats/data) | 12500 |\n",
    "| **total** | 13471 |\n",
    "\n",
    "#### Non Chat\n",
    "\n",
    "| Source | Total |\n",
    "| --------------| -----------|\n",
    "| [Caltech101](http://www.vision.caltech.edu/Image_Datasets/Caltech101/) | 9145 |\n",
    "| [inria](http://lear.inrialpes.fr/~jegou/data.php#holidays) | ?? |\n",
    "| [ukbench](https://archive.org/details/ukbench) | 2550 |\n",
    "| **total** | 11694 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un fois les datasets réunis, un nettoyage manuel des images qui peuvent prêter à confusion est nécessaire pour éviter des erreurs de prédictions liées à la qualité ou à l'ambiguïté de certaine photo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premiere Méthode ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La premiere initative prise pour la détection de la présence d'un chat sur une image a été d'utiliser la librairy python openCv qui implemente déja un système de détection avec des classifieurs déja entrainés pour la détection d'image basé sur le **haarcascade**.\n",
    "Un repository github regroupe déja tous un ensemble de **Haar classifieur**  pré-entrainé pour la détection d'object\n",
    "Dans ce repo un classifieur correspond déja à notre cas d'étude _haarcascadefrontalcatface.xml_\n",
    "Cette méthode considèrent des fenêtres de détection (ou masques) délimitant des zones rectangulaires adjacentes ; les intensités de pixels de ces rectangles sont additionnées, formant des sommes dont la différence constitue une caractéristique\n",
    "\n",
    "Ces caractérisques sont ensuite analysés pour déterminier si elles sont commune à l'object rechercher par le classifieur. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Haar](data/presentation/haar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deuxième Méthode ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les réseaux de neurones convolutif sont utilisé pour reconnaître des patterns visuels directement a partir des pixels d'une image avec un temps de calcul minimal. Ils peuvent reconnaîtres des patterns avec beaucoup de transformation (zoom, déformation, opacité etc...)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter les temps de cacul trop long, nous avons décidé de réduire la taile des images à 28px par 28px.\n",
    "Les Images sont traitées en RGB et ont deux états possibles dans notre liste de label (cat & noCat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Convolutional Neural Network](data/presentation/le_net.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le réseau de neurones multilayer, nous utilisons les récommandations indiqué pour la construction du celui-ci \n",
    "sous l'architecture **LeNet**\n",
    "\n",
    "INPUT => CONV => RELU => POOL => CONV => RELU => POOL => FC => RELU => FC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un traitement des datas est nécessaire pour pouvoir classifier chaque image en fonction d'un label. De plus, il faut redimensionner les différentes images et générer les datatset d'entrainement et de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un fois le traitement des dataset effectués, on entraîne notre réseau de neurone. \n",
    "Pour supporter plus de cas et s'adapter à la qualité des images nous transformons chaque image du dataset de manière aléatoire\n",
    "sur des paramètres comme la rotation, le zoom etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis une fois le model instancié nous utilisons la méthode fit de celui-ci pour entraîner le réseau de neurone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
